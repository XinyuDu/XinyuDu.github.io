---
title: "神经网络出现后的强化学习（深度强化学习）-DQN(deep Q-network)算法"
collection: teaching
type: "强化学习教程-2"
permalink: /teaching/2022-RL-2
venue: "杜新宇,京东"
date: 2022-03-17
location: "中国, 北京"
---

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

## 1.神经网络

### 1.1 网络结构

神经网络就是由输入层，隐藏层和输出层构成，如下图所示。一个神经网络只有一个输入层和一个输出层，可以有多个隐藏层。圆圈内的符号$$b_j^l$$是偏移量，上角标为所处的层数，下角标为位于本层从上到下数第几个。连线上的符号$$w_{jk}^l$$是权重，上角标表示箭头指向的神经元所处的层数，下角标第一个数字代表箭头指向的神经元所处的位置，第二个数字代表发起箭头的神经元所处的位置。输出箭头上的符号$$a_j^l$$表示第l层，第j个神经元的激活函数。

<img src="./2018-NeuralNetwork/1-6.png" />

### 1.2 训练机制

当我们构建了一个神经网络后，其最初的权重$$w_k$$和偏移量$$b_l$$都是随机的。这种神经网络并不能正确执行任务。我们还需要对其进行训练，使其在给定输入数据$$x$$时的输出$$o$$与$$x$$的标注值$$L(x)$$尽量相近，这种用于训练神经网络的数据集称为训练数据集。我们希望$$L(x)和o$$这两个向量之差的几何距离$$\parallel L(x)-o\parallel$$越短越好，几何距离越短神经网络的实际输出和我们期望的输出越相近。而且我们希望神经网络在训练数据集的所有训练数据上都实现短的几何距离，即要求$$\sum_{i=1}^n \parallel L(x)-o\parallel$$尽量小，该函数称为cost function。我们可以通过梯度下降及其衍生方法，来调整网络中的参数（权重和偏移量），使得cost function达到最小值。该过程就称作神经网络的训练过程。

## 2.用神经网络替换Q表格

## 3.算法

## 4.OpenAI gym环境
